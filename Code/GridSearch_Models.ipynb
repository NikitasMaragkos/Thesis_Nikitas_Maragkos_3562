{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f76b1443",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Ridge\n",
    "import xgboost as xgb\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation, LSTM, Conv1D, MaxPooling1D, Flatten\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import keras\n",
    "from keras.models import load_model\n",
    "from tensorflow.keras.layers import InputLayer\n",
    "import xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d4140f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('train_data.csv')\n",
    "test_data = pd.read_csv('test_data.csv')\n",
    "columns = train_data.drop(['PDB ID','G_experiment'], axis = 1).columns\n",
    "X_train = train_data.drop(['PDB ID','G_experiment'], axis = 1)\n",
    "Y_train = train_data['G_experiment']\n",
    "validation_size = int( 0.15 * len(X_train) )\n",
    "X_train = X_train[:-validation_size]\n",
    "Y_train = Y_train[:-validation_size]\n",
    "X_val = X_train[-validation_size:]\n",
    "Y_val = Y_train[-validation_size:]\n",
    "X_test  = test_data.drop(['PDB ID','G_experiment','RR_Predict_G', 'RFR_Predict_G', 'SVR_Predict_G',\n",
    "       'XGBR_Predict_G'], axis = 1)\n",
    "Y_test  = test_data['G_experiment']\n",
    "scaler = MinMaxScaler()\n",
    "s_scaler = StandardScaler()\n",
    "X_train_m = scaler.fit_transform(X_train)\n",
    "X_val_m = scaler.fit_transform(X_val)\n",
    "X_test_m  = scaler.transform(X_test)\n",
    "X_train_s = s_scaler.fit_transform(X_train)\n",
    "X_val_s = s_scaler.fit_transform(X_val)\n",
    "X_test_s  = s_scaler.transform(X_test)\n",
    "\n",
    "\n",
    "X_train_m_2, Y_train_m_2 = np.array(X_train_m), np.array(Y_train)\n",
    "X_val_m_2, Y_val_m_2 = np.array(X_val_m), np.array(Y_val)\n",
    "X_test_m_2, Y_test_m_2 = np.array(X_test_m), np.array(Y_test)\n",
    "X_train_s_2, Y_train_s_2 = np.array(X_train_m), np.array(Y_train)\n",
    "X_val_s_2, Y_val_s_2 = np.array(X_val_m), np.array(Y_val)\n",
    "X_test_s_2, Y_test_s_2 = np.array(X_test_m), np.array(Y_test)\n",
    "\n",
    "X_train_m_2 = X_train_m_2.reshape((X_train_m_2.shape[0], X_train_m_2.shape[1], 1))\n",
    "X_val_m_2 = X_val_m_2.reshape((X_val_m_2.shape[0], X_val_m_2.shape[1], 1)) \n",
    "X_test_m_2 = X_test_m_2.reshape((X_test_m_2.shape[0], X_test_m_2.shape[1], 1))\n",
    "X_train_s_2 = X_train_s_2.reshape((X_train_s_2.shape[0], X_train_s_2.shape[1], 1)) \n",
    "X_val_s_2 = X_val_s_2.reshape((X_val_s_2.shape[0], X_val_s_2.shape[1], 1)) \n",
    "X_test_s_2 = X_test_s_2.reshape((X_test_s_2.shape[0], X_test_s_2.shape[1], 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1ae8c19",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e93538ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.921906492799171 {'criterion': 'squared_error', 'max_depth': 10, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_leaf_nodes': 10}\n",
      "4.5712766625992165 {'criterion': 'squared_error', 'max_depth': 10, 'min_samples_split': 2, 'min_samples_leaf': 5, 'max_leaf_nodes': 15}\n"
     ]
    }
   ],
   "source": [
    "criterions = ['squared_error', 'friedman_mse' ]\n",
    "max_depths = [5, 10, 50 , 100]\n",
    "min_samples_splits = [ 2, 4, 10]\n",
    "min_leaf_samples = [1, 3, 5]\n",
    "max_leaf_nodes = [ 3, 5, 10, 15]\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "for criterion in criterions:\n",
    "    for max_depth in max_depths:\n",
    "        for min_samples_split in min_samples_splits:\n",
    "            for min_samples_leaf in min_leaf_samples:\n",
    "                for max_leaf_node in max_leaf_nodes:                \n",
    "                    dt_m = DecisionTreeRegressor(criterion = criterion, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_leaf_nodes = max_leaf_node)\n",
    "                    dt_s = DecisionTreeRegressor(criterion = criterion, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_leaf_nodes = max_leaf_node)\n",
    "                    dt_m.fit(X_train_m,Y_train)\n",
    "                    dt_s.fit(X_train_s,Y_train)\n",
    "                    pred_m = dt_m.predict(X_val_m)\n",
    "                    pred_s = dt_s.predict(X_val_s)\n",
    "                    mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                    mse_s = mean_squared_error(Y_val,pred_s)\n",
    "                    if mse_m < best_mse_m:\n",
    "                        best_mse_m = mse_m\n",
    "                        dt_best_params_m['criterion'] = criterion\n",
    "                        dt_best_params_m['max_depth'] = max_depth\n",
    "                        dt_best_params_m['min_samples_split'] = min_samples_split\n",
    "                        dt_best_params_m['min_samples_leaf'] = min_samples_leaf\n",
    "                        dt_best_params_m['max_leaf_nodes'] = max_leaf_node\n",
    "                    if mse_s < best_mse_s:\n",
    "                        best_mse_s = mse_s\n",
    "                        dt_best_params_s['criterion'] = criterion\n",
    "                        dt_best_params_s['max_depth'] = max_depth\n",
    "                        dt_best_params_s['min_samples_split'] = min_samples_split\n",
    "                        dt_best_params_s['min_samples_leaf'] = min_samples_leaf\n",
    "                        dt_best_params_s['max_leaf_nodes'] = max_leaf_node\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477561a4",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fbfeaab7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_8928\\977106522.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m                         \u001b[0mdt_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_depth\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_depth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_split\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_leaf_nodes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmax_leaf_node\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m                         \u001b[0mdt_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m                         \u001b[0mdt_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m                         \u001b[0mpred_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m                         \u001b[0mpred_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    448\u001b[0m             \u001b[1;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    449\u001b[0m             \u001b[1;31m# since correctness does not rely on using threads.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 450\u001b[1;33m             trees = Parallel(\n\u001b[0m\u001b[0;32m    451\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1046\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1047\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[0;32m    183\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"balanced\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_estimatorss = [5, 10, 50, 100]\n",
    "criterions = ['squared_error', 'friedman_mse' ]\n",
    "max_depths = [5, 10, 50 , 100]\n",
    "min_samples_splits = [ 2, 4, 10]\n",
    "min_leaf_samples = [1, 3, 5]\n",
    "max_leaf_nodes = [ 3, 5, 10, 15]\n",
    "rf_best_params_m = {}\n",
    "rf_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "for n_estimators in n_estimatorss:\n",
    "    for criterion in criterions:\n",
    "        for max_depth in max_depths:\n",
    "            for min_samples_split in min_samples_splits:\n",
    "                for min_samples_leaf in min_leaf_samples:\n",
    "                    for max_leaf_node in max_leaf_nodes:                \n",
    "                        dt_m = RandomForestRegressor(n_estimators, criterion = criterion, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_leaf_nodes = max_leaf_node)\n",
    "                        dt_s = RandomForestRegressor(n_estimators, criterion = criterion, max_depth = max_depth, min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf, max_leaf_nodes = max_leaf_node)\n",
    "                        dt_m.fit(X_train_m,Y_train)\n",
    "                        dt_s.fit(X_train_s,Y_train)\n",
    "                        pred_m = dt_m.predict(X_val_m)\n",
    "                        pred_s = dt_s.predict(X_val_s)\n",
    "                        mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                        mse_s = mean_squared_error(Y_val,pred_s)\n",
    "                        if mse_m < best_mse_m:\n",
    "                            best_mse_m = mse_m\n",
    "                            rf_best_params_m['n_estimators'] = n_estimators\n",
    "                            rf_best_params_m['criterion'] = criterion\n",
    "                            rf_best_params_m['max_depth'] = max_depth\n",
    "                            rf_best_params_m['min_samples_split'] = min_samples_split\n",
    "                            rf_best_params_m['min_samples_leaf'] = min_samples_leaf\n",
    "                            rf_best_params_m['max_leaf_nodes'] = max_leaf_node\n",
    "                        if mse_s < best_mse_s:\n",
    "                            best_mse_s = mse_s\n",
    "                            rf_best_params_s['n_estimators'] = n_estimators\n",
    "                            rf_best_params_s['criterion'] = criterion\n",
    "                            rf_best_params_s['max_depth'] = max_depth\n",
    "                            rf_best_params_s['min_samples_split'] = min_samples_split\n",
    "                            rf_best_params_s['min_samples_leaf'] = min_samples_leaf\n",
    "                            rf_best_params_s['max_leaf_nodes'] = max_leaf_node\n",
    "print(best_mse_m, rf_best_params_m)\n",
    "print(best_mse_s, rf_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a214be0",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d3c83c76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.3848711834145035 {'kernel': 'sigmoid', 'C': 50, 'gamma': 0.001, 'degree': 2}\n",
      "3.190967255666647 {'kernel': 'rbf', 'C': 50, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "kernels = ['rbf', 'poly', 'sigmoid']\n",
    "degrees = [2, 3, 4]\n",
    "Cs = [1, 5, 10, 50]\n",
    "gammas = [0.05, 0.01, 0.005, 0.001]\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "\n",
    "for kernel in kernels:\n",
    "    for C in Cs:\n",
    "        for gamma in gammas:\n",
    "            if kernel != 'poly':\n",
    "                svm_m = SVR(kernel = kernel, C = C, gamma = gamma)\n",
    "                svm_s = SVR(kernel = kernel, C = C, gamma = gamma)\n",
    "                svm_m.fit(X_train_m,Y_train)\n",
    "                svm_s.fit(X_train_s,Y_train)\n",
    "                pred_m = svm_m.predict(X_val_m)\n",
    "                pred_s = svm_s.predict(X_val_s)\n",
    "                mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                mse_s = mean_squared_error(Y_val,pred_s)\n",
    "                if mse_m < best_mse_m:\n",
    "                    best_mse_m = mse_m\n",
    "                    dt_best_params_m['kernel'] = kernel\n",
    "                    dt_best_params_m['C'] = C\n",
    "                    dt_best_params_m['gamma'] = gamma\n",
    "                if mse_s < best_mse_s:\n",
    "                    best_mse_s = mse_s\n",
    "                    dt_best_params_s['kernel'] = kernel\n",
    "                    dt_best_params_s['C'] = C\n",
    "                    dt_best_params_s['gamma'] = gamma\n",
    "            else:\n",
    "                for degree in degrees:\n",
    "                    svm_m = SVR(kernel = kernel, C = C, gamma = gamma, degree = degree)\n",
    "                    svm_s = SVR(kernel = kernel, C = C, gamma = gamma, degree = degree)\n",
    "                    svm_m.fit(X_train_m,Y_train)\n",
    "                    svm_s.fit(X_train_s,Y_train)\n",
    "                    pred_m = svm_m.predict(X_val_m)\n",
    "                    pred_s = svm_s.predict(X_val_s)\n",
    "                    mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                    mse_s = mean_squared_error(Y_val,pred_s)\n",
    "                    if mse_m < best_mse_m:\n",
    "                        best_mse_m = mse_m\n",
    "                        dt_best_params_m['kernel'] = kernel\n",
    "                        dt_best_params_m['C'] = C\n",
    "                        dt_best_params_m['gamma'] = gamma\n",
    "                        dt_best_params_m['degree'] = degree\n",
    "                    if mse_s < best_mse_s:\n",
    "                        best_mse_s = mse_s\n",
    "                        dt_best_params_s['kernel'] = kernel\n",
    "                        dt_best_params_s['C'] = C\n",
    "                        dt_best_params_s['gamma'] = gamma\n",
    "                        dt_best_params_s['degree'] = degree\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde2bb65",
   "metadata": {},
   "source": [
    "## K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "92a59047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.997087101148183 {'n_neighbors': 7}\n",
      "1.5890184141795267 {'n_neighbors': 2}\n"
     ]
    }
   ],
   "source": [
    "n_neighborss = [2, 3, 5, 7]\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "for n_neighbors in n_neighborss:\n",
    "    knn_m = KNeighborsRegressor(n_neighbors)\n",
    "    knn_s = KNeighborsRegressor(n_neighbors)\n",
    "    knn_m.fit(X_train_m,Y_train)\n",
    "    knn_s.fit(X_train_s,Y_train)\n",
    "    pred_m = knn_m.predict(X_val_m)\n",
    "    pred_s = knn_s.predict(X_val_s)\n",
    "    mse_m = mean_squared_error(Y_val,pred_m)\n",
    "    mse_s = mean_squared_error(Y_val,pred_s)\n",
    "    if mse_m < best_mse_m:\n",
    "        best_mse_m = mse_m\n",
    "        dt_best_params_m['n_neighbors'] = n_neighbors\n",
    "    if mse_s < best_mse_s:\n",
    "        best_mse_s = mse_s\n",
    "        dt_best_params_s['n_neighbors'] = n_neighbors\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76e51158",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e89dcc9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.514997000306236 {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.05}\n",
      "2.2959680168376075 {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.1}\n"
     ]
    }
   ],
   "source": [
    "depths = [10, 20, 50, 100, 600]\n",
    "lrs = [0.1, 0.05, 0.01, 0.001, 0.0005, 0.0001]\n",
    "estims = [10, 50, 100, 1000, 2000]\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "for depth in depths:\n",
    "    for lr in lrs:\n",
    "        for estim in estims:\n",
    "            knn_m = xgboost.XGBRegressor(n_estimators=estim, max_depth=depth, learning_rate = lr)\n",
    "            knn_s = xgboost.XGBRegressor(n_estimators=estim, max_depth=depth, learning_rate = lr)\n",
    "            knn_m.fit(X_train_m,Y_train)\n",
    "            knn_s.fit(X_train_s,Y_train)\n",
    "            pred_m = knn_m.predict(X_val_m)\n",
    "            pred_s = knn_s.predict(X_val_s)\n",
    "            mse_m = mean_squared_error(Y_val,pred_m)\n",
    "            mse_s = mean_squared_error(Y_val,pred_s)\n",
    "            if mse_m < best_mse_m:\n",
    "                best_mse_m = mse_m\n",
    "                dt_best_params_m['n_estimators'] = estim\n",
    "                dt_best_params_m['max_depth'] = depth\n",
    "                dt_best_params_m['learning_rate'] = lr\n",
    "            if mse_s < best_mse_s:\n",
    "                best_mse_s = mse_s\n",
    "                dt_best_params_s['n_estimators'] = estim\n",
    "                dt_best_params_s['max_depth'] = depth\n",
    "                dt_best_params_s['learning_rate'] = lr\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c4d3fc",
   "metadata": {},
   "source": [
    "## MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d9c37b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "5.741033988356952 {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.0005, 'neuron': [80, 50, 30, 10], 'final_activation': 'linear'}\n",
      "1.6095435423152222 {'n_estimators': 1000, 'max_depth': 10, 'learning_rate': 0.001, 'neuron': [100, 80, 50], 'final_activation': 'linear'}\n"
     ]
    }
   ],
   "source": [
    "def create_mlp(neurons, input_size, final_activation, learning_rate):\n",
    "    model_mlp = Sequential()\n",
    "    model_mlp.add(Dense(neurons[0], activation='relu', input_dim = input_size))\n",
    "    for neuron in neurons[1:]:\n",
    "        model_mlp.add(Dense(neuron, activation='relu'))\n",
    "    model_mlp.add(Dense(1, activation = final_activation))\n",
    "    model_mlp.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= learning_rate), loss = 'mean_squared_error')\n",
    "    return model_mlp\n",
    "\n",
    "neurons = [[50, 30, 10], [80, 50, 30, 10], [100, 80, 50], [ 30, 10]]\n",
    "final_activations = ['relu', 'linear']\n",
    "learning_rates = [0.1, 0.05, 0.01, 0.001, 0.0005]\n",
    "input_size = len(X_train_m[0])\n",
    "batch_size = 16\n",
    "total_epochs = 100\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "\n",
    "for neuron in neurons:\n",
    "    for final_activation in final_activations:\n",
    "        for learning_rate in learning_rates:\n",
    "            knn_m = create_mlp(neuron, input_size, final_activation, learning_rate)\n",
    "            knn_s = create_mlp(neuron, input_size, final_activation, learning_rate)\n",
    "            history_m = knn_m.fit(X_train_m,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            history_s = knn_s.fit(X_train_s,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            pred_m = knn_m.predict(X_val_m)\n",
    "            pred_s = knn_s.predict(X_val_s)\n",
    "            mse_m = mean_squared_error(Y_val,pred_m)\n",
    "            mse_s = mean_squared_error(Y_val,pred_s)\n",
    "            if mse_m < best_mse_m:\n",
    "                best_mse_m = mse_m\n",
    "                dt_best_params_m['neuron'] = neuron\n",
    "                dt_best_params_m['final_activation'] = final_activation\n",
    "                dt_best_params_m['learning_rate'] = learning_rate\n",
    "            if mse_s < best_mse_s:\n",
    "                best_mse_s = mse_s\n",
    "                dt_best_params_s['neuron'] = neuron\n",
    "                dt_best_params_s['final_activation'] = final_activation\n",
    "                dt_best_params_s['learning_rate'] = learning_rate\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d73100",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46509452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 15ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 16ms/step\n",
      "18/18 [==============================] - 1s 32ms/step\n",
      "18/18 [==============================] - 1s 33ms/step\n",
      "18/18 [==============================] - 3s 61ms/step\n",
      "18/18 [==============================] - 3s 78ms/step\n",
      "18/18 [==============================] - 1s 36ms/step\n",
      "18/18 [==============================] - 1s 36ms/step\n",
      "18/18 [==============================] - 1s 39ms/step\n",
      "18/18 [==============================] - 1s 37ms/step\n",
      "18/18 [==============================] - 1s 40ms/step\n",
      "18/18 [==============================] - 1s 40ms/step\n",
      "18/18 [==============================] - 1s 43ms/step\n",
      "18/18 [==============================] - 1s 43ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 13ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "18/18 [==============================] - 1s 14ms/step\n",
      "5.426601541081951 {'neuron': [80, 50, 30, 10], 'final_activation': 'linear', 'learning_rate': 0.001}\n",
      "5.333393428273475 {'neuron': [80, 50, 30, 10], 'final_activation': 'linear', 'learning_rate': 0.0005}\n"
     ]
    }
   ],
   "source": [
    "def create_lstm(neurons, input_size, final_activation, learning_rate):\n",
    "    model_mlp = Sequential()\n",
    "    model_mlp.add(LSTM(neurons[0], activation='relu', return_sequences=True, input_shape=(input_size[0], input_size[1])))\n",
    "    for neuron in neurons[1:-1]:\n",
    "        model_mlp.add(LSTM(neuron, activation='relu', return_sequences=True))\n",
    "    model_mlp.add(LSTM(5, activation = 'relu'))\n",
    "    model_mlp.add(Dense(1, activation = final_activation))\n",
    "    model_mlp.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= learning_rate), loss = 'mean_squared_error')\n",
    "    return model_mlp\n",
    "\n",
    "neurons = [[50, 30, 10], [80, 50, 30, 10], [100, 80, 50], [ 30, 10, 5]]\n",
    "final_activations = [ 'linear']\n",
    "learning_rates = [ 0.0001, 0.001, 0.0005]\n",
    "input_size = [X_train_m_2.shape[1], X_train_m_2.shape[2]]\n",
    "batch_size = 128\n",
    "total_epochs = 100\n",
    "\n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "\n",
    "for neuron in neurons:\n",
    "    for final_activation in final_activations:\n",
    "        for learning_rate in learning_rates:\n",
    "            knn_m = create_lstm(neuron, input_size, final_activation, learning_rate)\n",
    "            knn_s = create_lstm(neuron, input_size, final_activation, learning_rate)\n",
    "            history_m = knn_m.fit(X_train_m_2,Y_train_m_2, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            history_s = knn_s.fit(X_train_s_2,Y_train_s_2, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            pred_m = knn_m.predict(X_val_m_2)\n",
    "            pred_s = knn_s.predict(X_val_s_2)\n",
    "            try:\n",
    "                mse_m = mean_squared_error(Y_val_m_2,pred_m)\n",
    "                mse_s = mean_squared_error(Y_val_s_2,pred_s)\n",
    "            except:\n",
    "                continue\n",
    "            if mse_m < best_mse_m:\n",
    "                best_mse_m = mse_m\n",
    "                dt_best_params_m['neuron'] = neuron\n",
    "                dt_best_params_m['final_activation'] = final_activation\n",
    "                dt_best_params_m['learning_rate'] = learning_rate\n",
    "            if mse_s < best_mse_s:\n",
    "                best_mse_s = mse_s\n",
    "                dt_best_params_s['neuron'] = neuron\n",
    "                dt_best_params_s['final_activation'] = final_activation\n",
    "                dt_best_params_s['learning_rate'] = learning_rate\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7840c7e",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f6d5e9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 3ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 1ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "18/18 [==============================] - 0s 2ms/step\n",
      "5.315335101203674 {'filters': 16, 'kernel': 3, 'learning_rate': 0.0005}\n",
      "3.605669539725345 {'filters': 64, 'kernel': 7, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "def create_cnn(filters, kernel, input_size, final_activation, learning_rate):\n",
    "    model_mlp = Sequential()\n",
    "    model_mlp.add(Conv1D(filters=filters, kernel_size=kernel, activation='relu', input_shape=(input_size[0], input_size[1])))\n",
    "    model_mlp.add(MaxPooling1D(pool_size=2))\n",
    "    model_mlp.add(Flatten())\n",
    "    model_mlp.add(Dense(1, activation = final_activation))\n",
    "    model_mlp.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= learning_rate), loss = 'mean_squared_error')\n",
    "    return model_mlp\n",
    "\n",
    "filterss = [16, 32, 64]\n",
    "kernels = [3,5,7]\n",
    "final_activations = ['linear']\n",
    "learning_rates = [ 0.01, 0.001, 0.0005]\n",
    "input_size = [X_train_m_2.shape[1], X_train_m_2.shape[2]]\n",
    "batch_size = 16\n",
    "total_epochs = 100\n",
    "                     \n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "\n",
    "for filters in filterss:\n",
    "    for kernel in kernels:\n",
    "        for learning_rate in learning_rates:\n",
    "            knn_m = create_cnn(filters, kernel, input_size, final_activation, learning_rate)\n",
    "            knn_s = create_cnn(filters, kernel, input_size, final_activation, learning_rate)\n",
    "            history_m = knn_m.fit(X_train_m,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            history_s = knn_s.fit(X_train_s,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "            pred_m = knn_m.predict(X_val_m)\n",
    "            pred_s = knn_s.predict(X_val_s)\n",
    "            try:\n",
    "                mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                mse_s = mean_squared_error(Y_val,pred_s)\n",
    "            except:\n",
    "                continue\n",
    "            if mse_m < best_mse_m:\n",
    "                best_mse_m = mse_m\n",
    "                dt_best_params_m['filters'] = filters\n",
    "                dt_best_params_m['kernel'] = kernel\n",
    "                dt_best_params_m['learning_rate'] = learning_rate\n",
    "            if mse_s < best_mse_s:\n",
    "                best_mse_s = mse_s\n",
    "                dt_best_params_s['filters'] = filters\n",
    "                dt_best_params_s['kernel'] = kernel\n",
    "                dt_best_params_s['learning_rate'] = learning_rate\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8bc6d61",
   "metadata": {},
   "source": [
    "## LSTM-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a64cd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 24ms/step\n",
      "18/18 [==============================] - 1s 24ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 24ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 25ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 23ms/step\n",
      "18/18 [==============================] - 1s 21ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 22ms/step\n",
      "18/18 [==============================] - 1s 42ms/step\n",
      "18/18 [==============================] - 1s 43ms/step\n",
      "18/18 [==============================] - 1s 45ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 47ms/step\n",
      "18/18 [==============================] - 1s 48ms/step\n",
      "18/18 [==============================] - 1s 44ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 47ms/step\n",
      "18/18 [==============================] - 1s 47ms/step\n",
      "18/18 [==============================] - 1s 47ms/step\n",
      "18/18 [==============================] - 1s 47ms/step\n",
      "18/18 [==============================] - 1s 45ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 46ms/step\n",
      "18/18 [==============================] - 1s 51ms/step\n",
      "18/18 [==============================] - 1s 50ms/step\n",
      "18/18 [==============================] - 1s 51ms/step\n",
      "18/18 [==============================] - 1s 50ms/step\n",
      "18/18 [==============================] - 2s 55ms/step\n",
      "18/18 [==============================] - 1s 54ms/step\n",
      "18/18 [==============================] - 1s 52ms/step\n",
      "18/18 [==============================] - 1s 52ms/step\n",
      "18/18 [==============================] - 1s 53ms/step\n",
      "18/18 [==============================] - 1s 52ms/step\n",
      "18/18 [==============================] - 1s 50ms/step\n",
      "18/18 [==============================] - 1s 49ms/step\n",
      "18/18 [==============================] - 1s 54ms/step\n",
      "18/18 [==============================] - 1s 52ms/step\n",
      "18/18 [==============================] - 1s 51ms/step\n",
      "18/18 [==============================] - 1s 50ms/step\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17552\\2667305958.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     33\u001b[0m                 \u001b[0mknn_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_lstm_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mneuron\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal_activation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                 \u001b[0mhistory_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_m\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                 \u001b[0mhistory_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_s\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtotal_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     36\u001b[0m                 \u001b[0mpred_m\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_m\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_m\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m                 \u001b[0mpred_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mknn_s\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_s\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1648\u001b[0m                         ):\n\u001b[0;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1650\u001b[1;33m                             \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1651\u001b[0m                             \u001b[1;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 150\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    878\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    910\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m       (concrete_function,\n\u001b[0;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m--> 134\u001b[1;33m     return concrete_function._call_flat(\n\u001b[0m\u001b[0;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1745\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    376\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    377\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 378\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def create_lstm_cnn(neurons, filters, kernel, input_size, final_activation, learning_rate):\n",
    "    model_mlp = Sequential()\n",
    "    model_mlp.add(LSTM(neurons[0], activation='relu', return_sequences=True, input_shape=(input_size[0], input_size[1])))\n",
    "    for neuron in neurons[1:]:\n",
    "        model_mlp.add(LSTM(neuron, activation='relu', return_sequences=True))\n",
    "    model_mlp.add(Conv1D(filters=filters, kernel_size=kernel, activation='relu'))\n",
    "    model_mlp.add(MaxPooling1D(pool_size=2))\n",
    "    model_mlp.add(Flatten())\n",
    "    model_mlp.add(Dense(10, activation = 'relu'))\n",
    "    model_mlp.add(Dense(1, activation = final_activation))\n",
    "    model_mlp.compile(optimizer= tf.keras.optimizers.Adam(learning_rate= learning_rate), loss = 'mean_squared_error')\n",
    "    return model_mlp\n",
    "\n",
    "neurons = [[50, 30, 10], [80, 50, 30, 10], [100, 80, 50], [ 30, 10, 5]]\n",
    "filterss = [16, 32, 64]\n",
    "kernels = [3,5,7]\n",
    "final_activations = ['linear']\n",
    "learning_rates = [ 0.01, 0.001, 0.0005]\n",
    "input_size = [X_train_m_2.shape[1], X_train_m_2.shape[2]]\n",
    "batch_size = 128\n",
    "total_epochs = 100\n",
    "                     \n",
    "dt_best_params_m = {}\n",
    "dt_best_params_s = {}\n",
    "best_mse_m = float('inf')\n",
    "best_mse_s = float('inf')\n",
    "\n",
    "for neuron in neurons:\n",
    "    for filters in filterss:\n",
    "        for kernel in kernels:\n",
    "            for learning_rate in learning_rates:\n",
    "                knn_m = create_lstm_cnn(neuron, filters, kernel, input_size, final_activation, learning_rate)\n",
    "                knn_s = create_lstm_cnn(neuron, filters, kernel, input_size, final_activation, learning_rate)\n",
    "                history_m = knn_m.fit(X_train_m,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "                history_s = knn_s.fit(X_train_s,Y_train, batch_size= batch_size, epochs=total_epochs, verbose = 0)\n",
    "                pred_m = knn_m.predict(X_val_m)\n",
    "                pred_s = knn_s.predict(X_val_s)\n",
    "                try:\n",
    "                    mse_m = mean_squared_error(Y_val,pred_m)\n",
    "                    mse_s = mean_squared_error(Y_val,pred_s)\n",
    "                except:\n",
    "                    continue\n",
    "                if mse_m < best_mse_m:\n",
    "                    best_mse_m = mse_m\n",
    "                    dt_best_params_m['neuron'] = neuron\n",
    "                    dt_best_params_m['filters'] = filters\n",
    "                    dt_best_params_m['learning_rate'] = learning_rate\n",
    "                if mse_s < best_mse_s:\n",
    "                    best_mse_s = mse_s\n",
    "                    dt_best_params_s['neuron'] = neuron\n",
    "                    dt_best_params_s['filters'] = filters\n",
    "                    dt_best_params_s['kernel'] = kernel\n",
    "                    dt_best_params_s['learning_rate'] = learning_rate\n",
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "def18f59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.105683237353674 {'neuron': [50, 30, 10], 'filters': 32, 'kernel': 7, 'learning_rate': 0.001}\n",
      "4.21329445855553 {'neuron': [50, 30, 10], 'filters': 64, 'kernel': 7, 'learning_rate': 0.001}\n"
     ]
    }
   ],
   "source": [
    "print(best_mse_m, dt_best_params_m)\n",
    "print(best_mse_s, dt_best_params_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31d5a78",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
